{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43388f22-53f5-47c4-b32a-3944208406fc",
   "metadata": {},
   "source": [
    "# **Seminar - Functional 2P imaging analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbf100-a677-4b46-91dd-8141fac061ea",
   "metadata": {},
   "source": [
    "## Important Jupyter Notebook commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171fac2-5300-47d3-9ac5-2cc4f6b95b8c",
   "metadata": {},
   "source": [
    "**Execute a command field - 'Shift' + 'Enter'**  \n",
    "**Create a new command field above the selected field - 'Esc' + 'A'**  \n",
    "**Create a new command field below the selected field - 'Esc' + 'B'**  \n",
    "**Delete selected command field - 'Esc' + 2x'D'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db442105-4d78-4b85-b702-c94efd43e166",
   "metadata": {},
   "source": [
    "## Import of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1b7e1-5617-429b-ae7b-4c0ebb59a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import decomposition\n",
    "from random import randrange\n",
    "\n",
    "from kmeans_euclidean import KMeansEuclidean\n",
    "from kmeans_mahalanobis import KMeansMahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c304a4-e7d4-45e2-b8b1-92554e322923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c68647-3e90-45c4-977f-a59d5673afbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fed9fa-1b26-4fce-a26c-552429bc967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(Cell, df, save, save_path, cmap_c):\n",
    "    firing = df.pivot_table(Cell, 'Lap_2', '2_cm_binned_position')\n",
    "    stamps = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='sum')\n",
    "    avg_flour = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16,10), \n",
    "                             gridspec_kw={'height_ratios': [5, 1]});\n",
    "    sns.heatmap(firing, vmin=df[Cell].min(), vmax=df[Cell].max(), ax=axes[0], cmap=cmap_c);\n",
    "    sns.heatmap(avg_flour, annot=False, ax=axes[1], vmin=np.min(avg_flour.values), vmax=np.max(avg_flour.values), cmap=cmap_c);\n",
    "    if save == True:\n",
    "        fig.savefig(save_path, format='png')\n",
    "    #visualization.plot_contours(spatial_filtered[:, Cell], templates[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f53d15-bcdc-4772-b285-1cd33391d495",
   "metadata": {},
   "source": [
    "## **First steps - Import and inspect data**\n",
    "### Dataset background: One mouse on a linear treadmill, recorded under same task-settings on consecutive days. At one specified position the animal receives an automatic reward. Data is organized as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67e40d-835a-466a-a41b-3e88d5084657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset #1\n",
    "df_day1 = pd.read_excel('DataFrame_example_day1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552da29c-0052-4bcf-b607-ad0c3e1a1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset #2\n",
    "df_day2 = pd.read_excel('DataFrame_example_day2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4044b-36bc-4377-9886-f4f0ef2e4582",
   "metadata": {},
   "source": [
    "### Let's look at the dimensions of our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1126b0-e1c5-42cd-bd37-194904a00c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c82ed-3b43-46c1-817e-04727d099963",
   "metadata": {},
   "source": [
    "### We print the first 50 rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc971336-c624-4b10-af9b-eebf03e64b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_day1.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ed909-ad90-4db0-a6a9-f104c4ed48e2",
   "metadata": {},
   "source": [
    "### **Task:** What information can we derive from this? Can you explain what is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a77bf-fc36-4976-af52-26dae62be8c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Solution:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e66436-4682-48f3-a89d-6dbf04b61788",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### This is a bit hard to oversee and it becomes obvious, that we have to clean the data first. We can save the spiking data (actually: spiking probability) as a separate file 'neural_data'. In the data frame there is spiking data from 207 different neurons. There are also 32 frames at the beginning and at the end of the recording which are  empty, so we have to get rid of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc789464-b5af-497e-b02f-3625280a551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neural_data_day1 = df_day1.iloc[:, 15:-1]\n",
    "df_neural_data_day1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030fbef-e6ba-4b7d-9bfe-12cc72675b42",
   "metadata": {},
   "source": [
    "#### The rest of the data (e.g. position and velocity information) are storend in a different data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0e7ed-abca-4f28-a9ec-7bd656cf6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data_day1 = df_day1.iloc[:, :15]\n",
    "df_position_data_day1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d157d8f-ea67-4177-8b01-fed86a36b186",
   "metadata": {},
   "source": [
    "### Overview of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e45be-908e-43e3-9c7b-e8667c3204c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data_day1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725dc2a4-f230-4511-ba4f-66b0858beff7",
   "metadata": {},
   "source": [
    "### Now we can visualize some of the data like for example the velocity over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44829a8-46d2-46dd-bb9e-ac1c9d4bfb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data_day1['Velocity'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d873d-25fa-4964-b6ef-5c082bd22be1",
   "metadata": {},
   "source": [
    "### Or the position over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a375cd8-3b76-4407-92a9-6a5e434f8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_position_data_day1['Position'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3538f19-e455-44b8-a5e2-26e313f3bd05",
   "metadata": {},
   "source": [
    "### We can also plot the averaged velocity over position over all laps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352d081-780e-4e4c-9577-4439ffcd5b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define which data frame is used - in this case we use the data frame that contains the position information\n",
    "df = df_position_data_day1 \n",
    "\n",
    "# We aligne the data - in this case we calculate the average velocity for each 2 cm bin\n",
    "Velocity_over_Position = df.pivot_table(values='Velocity', index='Lap_2', columns='2_cm_binned_position', aggfunc='mean')\n",
    "\n",
    "# We plot the lap number against the averaged velocity per bin. The velocity is color-coded.\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(Velocity_over_Position, annot=False, ax=ax, cmap=\"coolwarm\")\n",
    "\n",
    "# The reward position is indicated by a red vertical line.\n",
    "ax.vlines(284/2, 0, 64, colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321fdf7-c10d-43e3-958f-2aa3eb87a86e",
   "metadata": {},
   "source": [
    "### **Question**: Can we draw conclusions about the behavior of the animal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf0a0d-1413-42c8-8087-b93776e0c2fe",
   "metadata": {},
   "source": [
    "## **Event triggered average**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688930c7-519c-4f39-ad31-9039332e3d62",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab709d93-7f91-4b81-8a17-c9b0ada8a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data = pd.read_excel('DataFrame_neural_data_event_triggered_avg.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0667d4-5f92-4171-8dd2-68d5760f47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking_data = pd.read_excel('DataFrame_spiking_data_event_triggered_avg.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05450057-385c-410f-aa13-509444d9285b",
   "metadata": {},
   "source": [
    "### **Task:** Check out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4397a50-ac4c-4fce-9ab7-f5ae8c392882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b62cd-6325-4e3c-b532-10c85ac3ce83",
   "metadata": {},
   "source": [
    "### Plot some examplary traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8530f-1118-4c01-b2cc-686f863179f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for cell in range(20):\n",
    "    plt.plot(neural_data[cell] + counter)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3313b4b-7407-4acb-9236-faba2266b490",
   "metadata": {},
   "source": [
    "### We further normalize the data by calculating the z-score for normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5830b7-88b0-4586-afed-c0b429f10a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-score from dFF (Optional)\n",
    "\n",
    "raw_calcium = neural_data.T.values\n",
    "#k = int(len(raw_calcium)/100*20)                    #uncomment if z-score is calculated from unnormalized data\n",
    "\n",
    "z_score = []\n",
    "\n",
    "for t in range(len(raw_calcium)):\n",
    "    arr = raw_calcium[t]\n",
    "    #F0 = arr.nsmallest(k).mean()\n",
    "    std = arr.std()\n",
    "    trace = arr/std                                  #if normalization is necessary: trace = (arr-F0)/std\n",
    "    z_score.append(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc49f2-9ff6-4395-bdf5-16eb248eed4e",
   "metadata": {},
   "source": [
    "### In this recording we see the hippocampal CA1 region where PV+ Interneurons are optogenetically stimulated. We want to find out how the circuit responds to this.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6eeaf8-4e89-45ea-8551-9d643d280727",
   "metadata": {},
   "source": [
    "### **Task:** Go into the recording and retrieve the starting frames of each train of optogenetic stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a5aff-959d-451c-9460-264de55eec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter the time stamps of each start frame:\n",
    "\n",
    "stimulation_start = np.asarray([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e86bd-6ce1-4760-92b5-da1676601264",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1bed1-17dd-4ae6-8bd3-049bbea69c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulation_start = np.array([2187, 3432, 4335, 5191, 6518])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb45608-d1a6-4e62-b649-6ca66ed36eb8",
   "metadata": {},
   "source": [
    "### For each neuron, we collect the individual responses to each optogenetic train. In total we have 5 trains of stimulation, so for each neuron we get 5 traces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa3f5f-b0a0-4848-ab88-39d432c84c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tuning_calcium_total = []   # Final list calcium\n",
    "event_tuning_spiking_total = []   # Final list spiking\n",
    "stim_idx = stimulation_start   # Stimulation marks\n",
    "n_data = z_score   # Neural data\n",
    "s_data = spiking_data.T.values   # Spiking data\n",
    "\n",
    "\n",
    "for neuron in range(len(n_data)):   # We loop through all cells in the dataset\n",
    "    event_tuning_neuron = []   # We collect the 5 calcium response traces for each neuron in this list\n",
    "    spiking_neuron = []   # Same for the spiking data\n",
    "    for e in range(len(stim_idx)):   # We loop through the stimulation marks\n",
    "        event_tuning_neuron.append(n_data[neuron][stim_idx[e]-160:stim_idx[e]+480])   # We retrieve a time window of -5 sec to +10 sec. In total 20 sec (or 640 frames)\n",
    "        spiking_neuron.append(s_data[neuron][stim_idx[e]-160:stim_idx[e]+480])      # Same for the spiking data\n",
    "    event_tuning_calcium_total.append(event_tuning_neuron)   # We append the 5 traces collected for the individual neuron to the final list\n",
    "    event_tuning_spiking_total.append(spiking_neuron)   # Same for the spiking data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25272b87-72b6-49f2-9145-fa8af9e8ce87",
   "metadata": {},
   "source": [
    "### Plot the 5 traces for an exemplary neuron. The red lines indicate the time window of stimulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1d1cf-ad98-42bd-ac8b-16c451c6463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 233\n",
    "\n",
    "sns.heatmap(event_tuning_calcium_total[neuron], cmap='jet')\n",
    "plt.vlines(x=160, ymin=5, ymax=0, color='red')\n",
    "plt.vlines(x=320, ymin=5, ymax=0, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa87fa-75e1-420c-a9aa-84cd22e2cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 233\n",
    "\n",
    "sns.heatmap(event_tuning_spiking_total[neuron], cmap='jet')\n",
    "plt.vlines(x=160, ymin=5, ymax=0, color='red')\n",
    "plt.vlines(x=320, ymin=5, ymax=0, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47e263-75d6-4d47-a7c6-0174eafe3208",
   "metadata": {},
   "source": [
    "### From this we now can calculate the average response for each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7282010-1b77-4dca-88e7-0e9c7ecf06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all averaged trial traces\n",
    "\n",
    "avg_trials = []\n",
    "avg_trials_spiking = []\n",
    "\n",
    "for cell in range(np.asarray(event_tuning_calcium_total).shape[0]):\n",
    "    avg_trials.append(np.mean(np.asarray(event_tuning_calcium_total)[cell], axis=0))\n",
    "    avg_trials_spiking.append(np.mean(np.asarray(event_tuning_spiking_total)[cell], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c59f20-caeb-4f7e-a0a9-a2f6e93eb628",
   "metadata": {},
   "source": [
    "### Plot all average traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fb265-f23b-4845-bed8-173ab7046a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,20));\n",
    "\n",
    "sns.heatmap(np.asarray(avg_trials)[:, 0:], cmap='jet', vmin=0.01)\n",
    "plt.vlines(x=160, ymin=810, ymax=0, color='red')\n",
    "plt.vlines(x=320, ymin=810, ymax=0, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de348116-f523-4005-a4fc-2a27a7c861d3",
   "metadata": {},
   "source": [
    "### **Question:** What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a15c0b-33c0-49ab-89f8-a65fbfca3c9d",
   "metadata": {},
   "source": [
    "## **Dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef64a85-3928-4a1e-8385-7b4108a0e634",
   "metadata": {},
   "source": [
    "### Next we prepare the data, so that we can perform principal component anaylsis (PCA). First we extract the part of the recording that we want to use for the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3e5ff-a1b3-46bf-8a3f-8a59c93e3c03",
   "metadata": {},
   "source": [
    "### **Task:** What part of the recording would make most sense? Enter the time points you want to use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46627c03-d01d-4b84-9b4b-09838515266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter starting frame and ending frame\n",
    "\n",
    "start_frame = \n",
    "end_frame = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88505346-278f-4ea3-a3e5-47f6599ebc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_data_postStim = np.asarray(avg_trials)[:, start_frame:end_frame].reshape(np.shape(np.asarray(avg_trials)[:, start_frame:end_frame])[0],np.shape(np.asarray(avg_trials)[:, start_frame:end_frame])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c36dd4-6d31-48b7-af40-3159596745aa",
   "metadata": {},
   "source": [
    "### Perform PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0bc79-b9a0-4e96-b935-13d9681e04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "pca = decomposition.PCA(n_components=4)\n",
    "# fit the model on training data\n",
    "pca.fit(neural_data_postStim)\n",
    "# transformation on 2D space\n",
    "pca_neural_data = pca.transform(neural_data_postStim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8098c67-8c35-4bc4-960a-5f3b78072b54",
   "metadata": {},
   "source": [
    "### Plot scatter plot of first 2 principal components (PCs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc50cd-3089-4258-aa85-916b18cff79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111)\n",
    "pcm = ax.scatter(pca_neural_data[:,0], pca_neural_data[:,1])\n",
    "#fig.colorbar(pcm, ax=ax)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fbbefe-6e27-4a8b-9487-b76170af68ee",
   "metadata": {},
   "source": [
    "### **Question:** What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe63ed-abb8-4a1c-8c00-38e5992da312",
   "metadata": {},
   "source": [
    "## **Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b50242-ead1-4543-811b-305a124c4aea",
   "metadata": {},
   "source": [
    "### Perform clustering on dimension-reduced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca56e1e-8a91-4b94-968c-3e5935f882c4",
   "metadata": {},
   "source": [
    "### **Question:** Where would you expect the clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d46db-dfab-4f93-9c55-31a950e9b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pca_neural_data\n",
    "\n",
    "kmeans_euclidean = KMeansEuclidean(2)\n",
    "y_kmeans_euclidean = kmeans_euclidean.fit(x).predict(x) # assign each smaple to a cluster\n",
    "\n",
    "#plot results\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_kmeans_euclidean, s=10, cmap='brg', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78661cb3-8c37-46f8-83ca-4a10a28d3f35",
   "metadata": {},
   "source": [
    "### Plot average traces separated according to their cluster identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb75d9b-edee-49e9-bd3d-c4759c8e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_InhEx_Traces = np.concatenate((np.asarray(avg_trials)[np.asarray(y_kmeans_euclidean) == 0][:, :], np.asarray(avg_trials)[np.asarray(y_kmeans_euclidean) == 1][:, :]))\n",
    "\n",
    "fig = plt.figure(figsize=(6, 16))\n",
    "\n",
    "gs = gridspec.GridSpec(16, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:14, :])\n",
    "ax1 = sns.heatmap(heatmap_InhEx_Traces, vmin=0.4, cmap='jet', cbar=False)\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "plt.vlines(x=160, ymin=810, ymax=0, color='yellow')\n",
    "plt.vlines(x=320, ymin=810, ymax=0, color='yellow')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[14:, :])\n",
    "ax2.plot(np.mean(np.asarray(avg_trials)[np.asarray(y_kmeans_euclidean) == 1][:,:], axis=0), color='green');\n",
    "ax2.plot(np.mean(np.asarray(avg_trials)[np.asarray(y_kmeans_euclidean) == 0][:,:], axis=0), color='blue');\n",
    "ax2.margins(x=0)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732a0f7-a0da-409c-8dd5-80ff00669f89",
   "metadata": {},
   "source": [
    "### There is a lot of noise due to the optogenetic stimulation. We can plot the inferred spiking to see the cleared response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56711dea-e59d-4db6-aa86-39a508b5ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_InhEx_Traces = np.concatenate((np.asarray(avg_trials_spiking)[np.asarray(y_kmeans_euclidean) == 0][:, :], np.asarray(avg_trials_spiking)[np.asarray(y_kmeans_euclidean) == 1][:, :]))\n",
    "\n",
    "fig = plt.figure(figsize=(6, 16))\n",
    "\n",
    "gs = gridspec.GridSpec(16, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:14, :])\n",
    "ax1 = sns.heatmap(heatmap_InhEx_Traces, cmap='jet', cbar=False)\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "plt.vlines(x=160, ymin=810, ymax=0, color='yellow')\n",
    "plt.vlines(x=320, ymin=810, ymax=0, color='yellow')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[14:, :])\n",
    "ax2.plot(np.mean(np.asarray(avg_trials_spiking)[np.asarray(y_kmeans_euclidean) == 1][:,:], axis=0), color='green');\n",
    "ax2.plot(np.mean(np.asarray(avg_trials_spiking)[np.asarray(y_kmeans_euclidean) == 0][:,:], axis=0), color='blue');\n",
    "ax2.margins(x=0)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216729d5-93ab-4732-9e6e-7ee0321dc5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_InhEx_Traces_BLPopulationActivity = np.concatenate((np.asarray(n_data)[np.asarray(y_kmeans_euclidean) == 0][:, :975], np.asarray(n_data)[np.asarray(y_kmeans_euclidean) == 1][:, :975]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af22762-9bd7-4c69-8473-75de4af59630",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 16))\n",
    "\n",
    "gs = gridspec.GridSpec(16, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:14, :])\n",
    "ax1 = sns.heatmap(heatmap_InhEx_Traces_BLPopulationActivity, vmin=0.01, cmap='jet', cbar=False)\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "#ax1.vlines(x=160, ymin=661, ymax=0, color='yellow')\n",
    "#ax1.vlines(x=320, ymin=661, ymax=0, color='yellow')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[14:, :])\n",
    "ax2.plot(np.mean(np.asarray(n_data)[np.asarray(y_kmeans_euclidean) == 1][:,:975], axis=0), color='green');\n",
    "ax2.plot(np.mean(np.asarray(n_data)[np.asarray(y_kmeans_euclidean) == 0][:,:975], axis=0), color='blue');\n",
    "ax2.margins(x=0)\n",
    "ax2.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94beefa6-5baf-40ba-8db7-51a336e4eef1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Spatial tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c19ff5-311b-4e52-9657-61563b206c77",
   "metadata": {},
   "source": [
    "### **Task:** Check out both data sets (df_day1 and df_day2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eead33-3b8f-4f1c-8ef5-84610f29b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7ec62-674a-4902-b5c2-66659bc99bb3",
   "metadata": {},
   "source": [
    "### Visualize running behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206171fa-8fb7-478d-9444-45029cfc087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which data frame is used - in this case we use the data frame that contains the position information\n",
    "df = df_day1 \n",
    "\n",
    "# We aligne the data - in this case we calculate the average velocity for each 2 cm bin\n",
    "Velocity_over_Position = df.pivot_table(values='Velocity', index='Lap_2', columns='2_cm_binned_position', aggfunc='mean')\n",
    "\n",
    "# We plot the lap number against the averaged velocity per bin. The velocity is color-coded.\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(Velocity_over_Position, annot=False, ax=ax, cmap=\"coolwarm\")\n",
    "\n",
    "# The reward position is indicated by a red vertical line.\n",
    "ax.vlines(284/2, 0, 64, colors='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a3602-6878-44dd-a2ab-e19e35e11fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which data frame is used - in this case we use the data frame that contains the position information\n",
    "df = df_day2 \n",
    "\n",
    "# We aligne the data - in this case we calculate the average velocity for each 2 cm bin\n",
    "Velocity_over_Position = df.pivot_table(values='Velocity', index='Lap_2', columns='2_cm_binned_position', aggfunc='mean')\n",
    "\n",
    "# We plot the lap number against the averaged velocity per bin. The velocity is color-coded.\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(Velocity_over_Position, annot=False, ax=ax, cmap=\"coolwarm\")\n",
    "\n",
    "# The reward position is indicated by a red vertical line.\n",
    "ax.vlines(284/2, 0, 71, colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76d7d6-eb55-403e-8dcb-b8842e762f42",
   "metadata": {},
   "source": [
    "### Check out spatial tuning of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8509cd-9eeb-40ec-a50c-0c3696a5df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data frame\n",
    "df = df_day2\n",
    "\n",
    "# Define Cell \n",
    "Cell = 122\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "gs = gridspec.GridSpec(9, 16, figure=fig)\n",
    "\n",
    "# Plot heatmap of averaged deltaF/F for each 2 cm bin\n",
    "ax1 = fig.add_subplot(gs[:7, :8])\n",
    "firing = df.pivot_table(Cell, 'Lap_2', '2_cm_binned_position')\n",
    "binned_avg = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='sum')\n",
    "ax1 = sns.heatmap(firing, vmin=df[Cell].min(), vmax=df[Cell].max(), ax=ax1, cmap='jet');\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "# Plot average over spatial bins\n",
    "ax2 = fig.add_subplot(gs[8:, :8])\n",
    "avg_flour = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "sns.heatmap(avg_flour, annot=False, ax=ax2, vmin=np.min(avg_flour.values), vmax=np.max(avg_flour.values), cmap='jet');\n",
    "ax2.axis('off')\n",
    "\n",
    "#Plot circular plot\n",
    "binned_mean = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "radii = binned_mean.to_numpy()\n",
    "\n",
    "ax3 = fig.add_subplot(gs[:8, 8:], polar=True)\n",
    "N = 180\n",
    "theta = np.arange(0.0, 2 * np.pi, 2 * np.pi / N)\n",
    "#radii = np.arange(0, N)\n",
    "width = 2*np.pi / N\n",
    "bars = ax3.bar(theta, radii[0], width=width, bottom=0.0, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd231e3-2a1a-4e28-906c-81fdedb91699",
   "metadata": {},
   "source": [
    "### This plotting is rather calculation power intensiv. The circular plot is not necessarily required for inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52d5c0-e67b-4509-a792-719aa5752687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data frame\n",
    "df = df_day2\n",
    "\n",
    "# Define target cell\n",
    "cell=23\n",
    "\n",
    "#Plot heatmap\n",
    "plot_heatmap(cell, df, save=False, save_path='U:/PostDoc/Teaching/Cell_279.png', cmap_c='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee424f-8f10-4ffe-81d4-de91eaa20dae",
   "metadata": {},
   "source": [
    "### **Task:** Explore the data. What are your thoughts? Specifically concider following points:  \n",
    "- **Is there a difference in representation between day 1 and day 2?**\n",
    "- **Do you observe events that you can relate to concepts previously learned in the course?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42e7f2-05f8-4a97-9ea1-7372e88ba4a8",
   "metadata": {},
   "source": [
    "## **Information rate**  \n",
    "Spiking of CA1 neurons obviously carries information about space. Therefore, in this chapter we are going to calculate the spatial information, which can be used as a metric for defining and quantifying place cell integrity. \n",
    "Following equation will be used:\n",
    "\n",
    "$\\sum \\limits _{j=1} ^{n} p_{i} \\frac{\\lambda_{i}}{\\lambda} log_{2} (\\frac{\\lambda_{i}}{\\lambda})$\n",
    "\n",
    "where λi the mean firing rate in the i-th bin, λ the overall mean firing rate and pi the probability \n",
    "of the animal being in the i-th bin (occupancy in the i-th bin/total recording time). Spatial \n",
    "information in bits/spike was obtained by dividing the information rate with the mean firing \n",
    "rate of the cell. (taken from: Hoydal et al, 2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66100a53-6b04-48a4-8c81-57257ed18759",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b88264-753c-425f-8a49-786f4c5d3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_rate(data_frame, cell):\n",
    "    occ_time = data_frame.pivot_table(values='Time_counter', columns='2_cm_binned_position', aggfunc='sum')/np.sum(data_frame.pivot_table(values='Time_counter', columns='2_cm_binned_position', aggfunc='sum').values)\n",
    "    bfr = data_frame.pivot_table(values=cell, columns='2_cm_binned_position', aggfunc='sum').values/(data_frame.pivot_table(values='Time_counter', columns='2_cm_binned_position', aggfunc='sum').values/30)\n",
    "    mfr = data_frame[cell].sum()/data_frame['Time'].max()\n",
    "    bits_per_spike = np.nansum(occ_time.values*(bfr/mfr)*np.log(bfr/mfr)/np.log(2))\n",
    "    return bits_per_spike\n",
    "\n",
    "def bootstrap_fragments_shuffled(df, cell, Samples, window_size):\n",
    "    peaks = []\n",
    "    for m in range(Samples):\n",
    "        fl_trace = np.array_split(df[cell], window_size)\n",
    "        shuf_trace = shuffle(fl_trace)\n",
    "        shuf_trace = pd.concat(shuf_trace)\n",
    "        shuffled_df = pd.DataFrame({'Cell': shuf_trace.values, 'Position_binned': df['Position_binned'].values})\n",
    "        avg_flour_shuffled = shuffled_df.pivot_table(values='Cell', columns='Position_binned', aggfunc='mean')\n",
    "        peak_value = avg_flour_shuffled.T.max().values[0]\n",
    "        peaks.append(peak_value)\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d68e8-f544-4ece-960b-18b0c386e5d4",
   "metadata": {},
   "source": [
    "### Load example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c9ba5-0851-42d6-8e93-3b5086518dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset #2\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_spiking_day2 = pd.read_excel('DataFrame_example_spiking_day2.xlsx')\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4591cd-035c-4fec-8c1e-009ffca7df3f",
   "metadata": {},
   "source": [
    "### Calculate spatial information for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ce1e2-0b58-47b9-ba2c-55be71fcb475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_spiking_day2.loc[df_spiking_day2['Velocity'] > 2]\n",
    "\n",
    "spatial_information_results = []\n",
    "\n",
    "for cell in range(698):\n",
    "    cell_spatial_information = calculate_information_rate(df, cell)\n",
    "    spatial_information_results.append(cell_spatial_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38761830-b985-4ddd-b1d5-7b7941c324fb",
   "metadata": {},
   "source": [
    "### **Task:** The cells can be sorted according to their spatial information value (ascending order). Check out the cells with low spatial information score and those with high spatial infromation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d442a-e054-4aeb-9eab-4ab7e5ba015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(spatial_information_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a01d39-bc2f-47b4-9ea2-b3185dc53e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cell with highest score: Cell# {} - {}'.format(np.argsort(spatial_information_results)[-1], spatial_information_results[np.argsort(spatial_information_results)[-1]]))\n",
    "print('Cell with lowest score: Cell# {} - {}'.format(np.argsort(spatial_information_results)[1], spatial_information_results[np.argsort(spatial_information_results)[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c91ce6-c5e3-48dd-ab70-3efd51ecae0a",
   "metadata": {},
   "source": [
    "### Now we can visualize the spatial firing (spiking) for individual cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1554c-4ea4-475b-89db-1ef1f2e4278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data frame\n",
    "df = df_spiking_day2.loc[df_spiking_day2['Velocity'] > 2]\n",
    "\n",
    "# Define Cell \n",
    "Cell = 449\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "gs = gridspec.GridSpec(9, 16, figure=fig)\n",
    "\n",
    "# Plot heatmap of averaged deltaF/F for each 2 cm bin\n",
    "ax1 = fig.add_subplot(gs[:7, :8])\n",
    "firing = df.pivot_table(Cell, 'Lap_2', '2_cm_binned_position')\n",
    "binned_avg = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='sum')\n",
    "ax1 = sns.heatmap(firing, vmin=df[Cell].min(), vmax=df[Cell].max(), ax=ax1, cmap='jet');\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "# Plot average over spatial bins\n",
    "ax2 = fig.add_subplot(gs[8:, :8])\n",
    "avg_flour = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "sns.heatmap(avg_flour, annot=False, ax=ax2, vmin=np.min(avg_flour.values), vmax=np.max(avg_flour.values), cmap='jet');\n",
    "ax2.axis('off')\n",
    "\n",
    "#Plot circular plot\n",
    "binned_mean = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "radii = binned_mean.to_numpy()\n",
    "\n",
    "ax3 = fig.add_subplot(gs[:8, 8:], polar=True)\n",
    "N = 180\n",
    "theta = np.arange(0.0, 2 * np.pi, 2 * np.pi / N)\n",
    "#radii = np.arange(0, N)\n",
    "width = 2*np.pi / N\n",
    "bars = ax3.bar(theta, radii[0], width=width, bottom=0.0, color='red')\n",
    "\n",
    "#plt.savefig(save_path, format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1c35f-2534-47a0-a524-5eadbbaae70d",
   "metadata": {},
   "source": [
    "### Compared to the z-scored version, this looks much more sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ae173-065c-424a-a3d3-b0b2e6d6e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data frame\n",
    "df = df_day2\n",
    "\n",
    "# Define Cell \n",
    "Cell = 380\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "gs = gridspec.GridSpec(9, 16, figure=fig)\n",
    "\n",
    "# Plot heatmap of averaged deltaF/F for each 2 cm bin\n",
    "ax1 = fig.add_subplot(gs[:7, :8])\n",
    "firing = df.pivot_table(Cell, 'Lap_2', '2_cm_binned_position')\n",
    "binned_avg = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='sum')\n",
    "ax1 = sns.heatmap(firing, vmin=df[Cell].min(), vmax=df[Cell].max(), ax=ax1, cmap='jet');\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "# Plot average over spatial bins\n",
    "ax2 = fig.add_subplot(gs[8:, :8])\n",
    "avg_flour = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "sns.heatmap(avg_flour, annot=False, ax=ax2, vmin=np.min(avg_flour.values), vmax=np.max(avg_flour.values), cmap='jet');\n",
    "ax2.axis('off')\n",
    "\n",
    "#Plot circular plot\n",
    "binned_mean = df.pivot_table(values=Cell, columns='2_cm_binned_position', aggfunc='mean')\n",
    "radii = binned_mean.to_numpy()\n",
    "\n",
    "ax3 = fig.add_subplot(gs[:8, 8:], polar=True)\n",
    "N = 180\n",
    "theta = np.arange(0.0, 2 * np.pi, 2 * np.pi / N)\n",
    "#radii = np.arange(0, N)\n",
    "width = 2*np.pi / N\n",
    "bars = ax3.bar(theta, radii[0], width=width, bottom=0.0, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d6e40c-bbe0-4d59-b16d-f7a9d1d114cb",
   "metadata": {},
   "source": [
    "### **Question:** Do you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eafed7-0911-4f29-8b6e-0bb53f3eae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "# Plot the dF/F\n",
    "plt.plot(df_day2[380-1].values[18000:19000]*3, color='blue')\n",
    "\n",
    "# For comparison, plot the inferred spiking in blue\n",
    "plt.plot(df_spiking_day2[380].values[18000:19000]*32, color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1b3f3-abbf-4966-bff6-8178526f60d1",
   "metadata": {},
   "source": [
    "## **Bootstrapping**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe6d3d-34b5-48dd-af6b-9e364828244a",
   "metadata": {},
   "source": [
    "### \"Bootstrapping statistics is a form of hypothesis testing that involves resampling a single data set to create a multitude of simulated samples. Those samples are used to calculate standard errors, confidence intervals and for hypothesis testing.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ed6d1-6406-4405-a899-0cb051c8569c",
   "metadata": {},
   "source": [
    "### We split the recording (velocity > 2 cm/sec) for an individual cell into random-sized (5 sec < 10 sec) snipplets and reassamble them in random order. From this we calculate the new peak firing rate and compare it to the original one. This we repeat 500 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10092803-6ad3-4eb5-9597-2039ad8c2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_spiking_day2.loc[df_spiking_day2['Velocity'] > 2]\n",
    "start = time.time()\n",
    "\n",
    "frame_rate = 32\n",
    "cell = 380\n",
    "bst_test_2 = bootstrap_fragments_shuffled(df=df, cell=cell, Samples=500, window_size=int(len(df[cell])/randrange(frame_rate*5, frame_rate*10)))\n",
    "plt.hist(bst_test_2, bins=300, range=(0,0.6))\n",
    "plt.axvline(df.pivot_table(values=cell, columns='2_cm_binned_position', aggfunc='mean').T.max().values[0], color='red')\n",
    "\n",
    "bst_result = bst_test_2 < df.pivot_table(values=cell, columns='2_cm_binned_position', aggfunc='mean').T.max().values[0]\n",
    "print(\"Percentage of smaller peaks: {}%\".format((np.count_nonzero(bst_result == True)/(len(bst_result)/100))))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67f834-febd-481c-b5a6-b535cfe95972",
   "metadata": {},
   "source": [
    "### No we create a data frame that contains the peak value, peak position and mutual information score for each neuron in our recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44665d04-6e11-4647-b7bc-5f1d293fa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_spiking_day2\n",
    "\n",
    "pc_peaks = []\n",
    "pc_peak_pos = []\n",
    "pc_information_rate = []\n",
    "\n",
    "for c in range(697):\n",
    "    peak_value = df.pivot_table(values=c, columns='Position_binned', aggfunc='mean').T.max().values[0]\n",
    "    peak_pos = df.pivot_table(values=c, columns='Position_binned', aggfunc='mean').T.idxmax().values[0]\n",
    "    inf_rate = calculate_information_rate(df, c)\n",
    "    #print(peak_pos)\n",
    "    pc_peaks.append(peak_value)\n",
    "    pc_peak_pos.append(peak_pos)\n",
    "    pc_information_rate.append(inf_rate)\n",
    "\n",
    "df_place_cell_evaluation = pd.DataFrame({'Peak value': pc_peaks, 'Peak position': pc_peak_pos, 'Information rate': pc_information_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc9802-daef-433c-a23d-b4542eeb780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_cell_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77bcb9-f034-4d7d-a292-82a0cb24bde0",
   "metadata": {},
   "source": [
    "### Next we perform the bootstrapping. This is commented-out, because it would take an hour to run. Please load the prepared data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951f588-0b65-4aec-8a1b-1a7f8a195a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_spiking_day2\n",
    "#shuffled_peaks = []\n",
    "\n",
    "#frame_rate = 32\n",
    "\n",
    "#start = time.time()\n",
    "#for c in range(698):\n",
    "    #peak_values = bootstrap_fragments_shuffled(\n",
    "        #df=df, cell=c, Samples=500, window_size=int(len(df[c])/randrange(frame_rate*5, frame_rate*10)))\n",
    "    #mask = peak_values < df.pivot_table(values=c, columns='Position_binned', aggfunc='mean').T.max().values[0]\n",
    "    #shuffled_peaks.append(np.count_nonzero(mask == True)/(len(mask)/100))\n",
    "    \n",
    "#end = time.time()\n",
    "#print(end - start)\n",
    "    \n",
    "#df_place_cell_evaluation['Percentile of smaller peaks'] = shuffled_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb8937-872d-4bf0-b206-8a3f425a21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_place_cell_evaluation.to_excel('U:/PostDoc/Teaching/place_cell_evaluation.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903ff48-b83e-474d-85d8-29983a90bff0",
   "metadata": {},
   "source": [
    "### Load data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10d685-8fad-4d34-8174-b3ff792959b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_cell_evaluation = pd.read_excel(\n",
    "    'Place_cell_evaluation.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934a6e4-ad14-42b7-8011-fd7f4170f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_cell_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857845c4-501c-46d5-a8a3-b479183fdcb4",
   "metadata": {},
   "source": [
    "### Select only those neurons that have >95% fraction of smaller peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fb688-532f-466b-9488-115a168bf300",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = df_place_cell_evaluation\n",
    "df_moving = df_spiking_day2[df_spiking_day2['Velocity'] > 2]\n",
    "\n",
    "idxLst = []\n",
    "\n",
    "for c in (np.asarray(target_df.loc[target_df['Percentile of smaller peaks'] > 95].index)):\n",
    "    idxLst.append(np.argmax(df_moving.pivot_table(values=c, columns='5_cm_binned_position', aggfunc='mean')))\n",
    "          \n",
    "dic = {'Identified place cells' : np.asarray(target_df.loc[target_df['Percentile of smaller peaks'] > 95].index), 'Peak Idx' : idxLst, 'Inf rate' : np.asarray(target_df['Information rate'].loc[target_df['Percentile of smaller peaks'] > 95])}\n",
    "df_place_cells = pd.DataFrame(data=dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cb8d9-6ee5-425a-ac74-b1a322fe0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3968b-29d5-4111-978a-8c08df2989c5",
   "metadata": {},
   "source": [
    "### Sort those neurons according to their peak position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29c2a5-a9f1-4a6b-9bc4-ec91c10aa269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_cell_sorted = df_place_cells.sort_values(by = 'Peak Idx', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2149c7-e47d-4795-b355-19fd09876f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place_cell_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aac040-4b93-44d7-9ba2-e722ff4bca1b",
   "metadata": {},
   "source": [
    "### Plot ordered cells as heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58020ae5-4317-421f-a6c9-919eeaafd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlaceCellsSorted = []\n",
    "PlaceCellsNormSorted = []\n",
    "\n",
    "df_moving = df_spiking_day2.iloc[32:-32, :][df_spiking_day2.iloc[32:-32, :]['Velocity'] > 2]\n",
    "df = df_place_cells.sort_values(by = 'Peak Idx', ascending=False, ignore_index=True)\n",
    "count = 0\n",
    "\n",
    "for c in df['Identified place cells'].values:\n",
    "    s = df_moving.pivot_table(values=c, columns='2_cm_binned_position', aggfunc='mean').values[0]\n",
    "    #print(s.max())\n",
    "    scaler = MinMaxScaler()\n",
    "    t = scaler.fit_transform(s.reshape(-1,1))\n",
    "    #print(t.max())\n",
    "    PlaceCellsSorted.append(s)\n",
    "    PlaceCellsNormSorted.append(t.T[0])\n",
    "    count = count + 1\n",
    "    #print(count)\n",
    "    \n",
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.heatmap(PlaceCellsNormSorted, cmap='YlGnBu_r')   #YlGnBu_r\n",
    "\n",
    "plt.vlines(48.4/2, 0, 325, linestyles='dashed', colors='white')\n",
    "plt.vlines(103.2/2, 0, 325, linestyles='dashed', colors='yellow')\n",
    "\n",
    "plt.vlines(164.8/2, 0, 325, linestyles='dashed', colors='white')\n",
    "plt.vlines(222.4/2, 0, 325, linestyles='dashed', colors='yellow')\n",
    "\n",
    "plt.vlines(284/2, 0, 325, linestyles='dashed', colors='red')\n",
    "plt.vlines(346/2, 0, 325, linestyles='dashed', colors='yellow')\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,\n",
    "    left=False,       # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "\n",
    "#plt.savefig('U:/PostDoc/Workshops/CAJAL 2023/Place_cell_map.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8031552-5598-45d4-9a17-f68b3a327b3f",
   "metadata": {},
   "source": [
    "### Plot the average population activity of those place cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91137f38-3182-4a96-a517-af2415ff084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.plot(np.mean(PlaceCellsNormSorted, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e333524-923e-4609-bb80-0148af3c5c75",
   "metadata": {},
   "source": [
    "### **Question:** What can we conclude from this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc901380-1e49-49a4-a05c-f994babd1b54",
   "metadata": {},
   "source": [
    "### Other representation (line-plot) of the ordered place cells (just because it looks nice ;))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558eb0db-f2c2-4a73-a4df-5abcbe7f08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "for trace in PlaceCellsNormSorted:\n",
    "    plt.plot(trace*15 + counter, color='grey', linewidth=0.4)\n",
    "    counter = counter - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4fe01-3be6-4576-b716-e0b19d0ae425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
